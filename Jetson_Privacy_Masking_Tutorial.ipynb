{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "939ab70f",
   "metadata": {},
   "source": [
    "\n",
    "# Jetson RGB‑D Privacy Masking Tutorial (RealSense → Fast Pixelate)\n",
    "\n",
    "This notebook is an **instructional companion** for your Jetson setup. It covers:\n",
    "\n",
    "1. Environment checks (PyTorch, CUDA, TensorRT, ONNX Runtime)\n",
    "2. Initializing `AVPrivacyMasker` and verifying providers\n",
    "3. Building masks two ways: **depth‑guided** and **box‑only (elliptical)** \n",
    "4. Running the anonymization loop on a directory of images (offline)\n",
    "5. (Optional) Live RealSense → **MJPEG over HTTP** streaming server\n",
    "6. Computing **Dice** and **Recall** vs. SAM masks\n",
    "7. Troubleshooting\n",
    "\n",
    "> **Note:** Some cells require your Jetson + camera. They’re safe to run; if a device/library is missing, the cells will explain what to install/enable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce4594e",
   "metadata": {},
   "source": [
    "## 1) Environment checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4d5560f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.12 (main, May 27 2025, 17:12:29) [GCC 11.4.0]\n",
      "Platform: Linux-5.15.148-tegra-aarch64-with-glibc2.35\n",
      "Torch: 2.5.0a0+872d972e41.nv24.08\n",
      "CUDA available: True\n",
      "CUDA device: Orin\n",
      "cuDNN: 90300\n",
      "ONNX Runtime: 1.23.0\n",
      "Available providers: ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      "OpenCV: 4.11.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys, os, platform\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Platform:\", platform.platform())\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    print(\"Torch:\", torch.__version__)\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA device:\", torch.cuda.get_device_name(0))\n",
    "        import torch.backends.cudnn as cudnn\n",
    "        print(\"cuDNN:\", cudnn.version())\n",
    "except Exception as e:\n",
    "    print(\"PyTorch not available:\", e)\n",
    "\n",
    "try:\n",
    "    import onnxruntime as ort\n",
    "    print(\"ONNX Runtime:\", ort.__version__)\n",
    "    print(\"Available providers:\", ort.get_available_providers())\n",
    "except Exception as e:\n",
    "    print(\"ONNX Runtime not available:\", e)\n",
    "\n",
    "try:\n",
    "    import cv2\n",
    "    print(\"OpenCV:\", cv2.__version__)\n",
    "except Exception as e:\n",
    "    print(\"OpenCV not available:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bfb73b",
   "metadata": {},
   "source": [
    "## 2) Initialize `AVPrivacyMasker`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2b4a184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "model ignore: /home/jetsonuser/.insightface/models/buffalo_s/1k3d68.onnx landmark_3d_68\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "model ignore: /home/jetsonuser/.insightface/models/buffalo_s/2d106det.onnx landmark_2d_106\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "find model: /home/jetsonuser/.insightface/models/buffalo_s/det_500m.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "model ignore: /home/jetsonuser/.insightface/models/buffalo_s/genderage.onnx genderage\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
      "model ignore: /home/jetsonuser/.insightface/models/buffalo_s/w600k_mbf.onnx recognition\n",
      "set det-size: (640, 640)\n",
      "[ORT] detection providers -> ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      "Masker initialized.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# If your av_privacy_masker.py is not importable, set its folder here:\n",
    "# import sys; sys.path.insert(0, '/path/to/your/module/folder')\n",
    "\n",
    "from av_privacy_masker import AVPrivacyMasker\n",
    "mp = AVPrivacyMasker(\n",
    "    device=\"cuda\",\n",
    "    conf_thresh=0.5,\n",
    "    anon_block=24,\n",
    "    anon_noise=20,\n",
    "    dilate_kernel=13,\n",
    "    det_size=(640, 640),\n",
    "    verbose=True,\n",
    "    enable_depth_anon=False,\n",
    ")\n",
    "\n",
    "print(\"Masker initialized.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3755982",
   "metadata": {},
   "source": [
    "## 3) Mask construction demo (box‑only vs depth‑guided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5c7e9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[detect_faces] boxes=[[405, 128, 530, 260], [129, 56, 253, 201]]\n",
      "[detect_faces] boxes=[[405, 128, 530, 260], [129, 56, 253, 201]]\n",
      "Mask pixels (box-only): 68714\n",
      "Preview saved to /home/jetsonuser/masking/demo/data/mask_box_demo.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np, cv2, torch, time\n",
    "\n",
    "# Read in demo image\n",
    "H, W = 480, 640\n",
    "bgr = cv2.imread(\"/home/jetsonuser/masking/demo/data/demo_image.png\")\n",
    "assert bgr is not None, \"Image not found\"\n",
    "\n",
    "# detect faces and yield bounding boxes\n",
    "boxes = mp.detect_faces(bgr)  # e.g., [[204,127,405,428],[648,283,848,555]]\n",
    "print(f\"[detect_faces] boxes={boxes}\")\n",
    "\n",
    "# Box-only mask (elliptical, with padding and dilation inside the class)\n",
    "mask_box = mp.build_mask_from_boxes(boxes, bgr.shape, pad_ratio=0.25, oval=True)\n",
    "\n",
    "# Visualize: black out masked region\n",
    "vis = bgr.copy()\n",
    "mask_bool = mask_box.astype(bool) if mask_box.dtype != np.bool_ else mask_box\n",
    "vis[mask_bool] = (0, 0, 0)\n",
    "\n",
    "# Save preview (make sure path has a filename + extension)\n",
    "out_dir = \"/home/jetsonuser/masking/demo/data\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "out_path = os.path.join(out_dir, \"mask_box_demo.png\")\n",
    "ok = cv2.imwrite(out_path, vis)\n",
    "assert ok, f\"Failed to write image to {out_path}\"\n",
    "\n",
    "print(\"Mask pixels (box-only):\", int(mask_box.sum()))\n",
    "print(f\"Preview saved to {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb9c449",
   "metadata": {},
   "source": [
    "## 4) Offline batch anonymization (images → masked images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2a6b1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[detect_faces] boxes=[[405, 128, 530, 260], [129, 56, 253, 201]]\n",
      "Processed 1 images in 0.16s (6.3 FPS). Output: /home/jetsonuser/masking/demo/data/demo_out\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "in_dir = Path(\"/home/jetsonuser/masking/demo/data/demo_images\")\n",
    "out_dir = Path(\"/home/jetsonuser/masking/demo/data/demo_out\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def is_img(p):\n",
    "    return p.suffix.lower() in {\".jpg\", \".jpeg\", \".png\", \".bmp\"}\n",
    "\n",
    "# Gather input images\n",
    "paths = [p for p in in_dir.glob(\"*\") if is_img(p)]\n",
    "if not paths:\n",
    "    print(\"Put a few images into\", in_dir, \"then rerun this cell.\")\n",
    "else:\n",
    "    t0 = time.perf_counter()\n",
    "    n = 0\n",
    "    for p in paths:\n",
    "        bgr = cv2.imread(str(p), cv2.IMREAD_COLOR)\n",
    "        if bgr is None:\n",
    "            continue\n",
    "\n",
    "        # Detect faces\n",
    "        boxes = mp.detect_faces(bgr)\n",
    "\n",
    "        # Box-only mask (fast; no depth file in this demo)\n",
    "        mask = mp.build_mask_from_boxes(\n",
    "            boxes, bgr.shape, pad_ratio=0.25, oval=True\n",
    "        )\n",
    "\n",
    "        # Anonymize\n",
    "        out = mp.fast_pixelate(\n",
    "            bgr, mask, block=mp.anon_block, noise=mp.anon_noise\n",
    "        )\n",
    "\n",
    "        # Save anonymized output (same filename as input)\n",
    "        cv2.imwrite(str(out_dir / p.name), out)\n",
    "        n += 1\n",
    "\n",
    "    dt = time.perf_counter() - t0\n",
    "    fps = n / dt if dt > 0 else 0\n",
    "    print(f\"Processed {n} images in {dt:.2f}s ({fps:.1f} FPS). Output:\", out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772c91ef",
   "metadata": {},
   "source": [
    "## 5) Dice & Recall vs SAM masks (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a0d50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def dice_and_recall(pred: np.ndarray, gt: np.ndarray):\n",
    "    # pred, gt: uint8 {0,1} HxW\n",
    "    tp = int(((pred==1)&(gt==1)).sum())\n",
    "    fp = int(((pred==1)&(gt==0)).sum())\n",
    "    fn = int(((pred==0)&(gt==1)).sum())\n",
    "    dice = (2*tp) / (2*tp + fp + fn) if (2*tp + fp + fn) > 0 else 1.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 1.0\n",
    "    return dice, recall, tp, fp, fn\n",
    "\n",
    "# Example layout:\n",
    "# /path/to/sam_masks/session_key.npy   -> shape (T, H, W) uint8\n",
    "# /path/to/our_masks/session_key.npy   -> shape (T, H, W) uint8\n",
    "our_np_path = Path(\"/mnt/data/our_masks_example.npy\")  # change to your file\n",
    "sam_np_path = Path(\"/mnt/data/sam_masks_example.npy\")\n",
    "\n",
    "if our_np_path.exists() and sam_np_path.exists():\n",
    "    our = np.load(our_np_path)    # (T,H,W)\n",
    "    sam = np.load(sam_np_path)    # (T,H,W)\n",
    "    T = min(len(our), len(sam))\n",
    "    assert our.shape[1:]==sam.shape[1:], \"H/W mismatch\"\n",
    "    dices = []; recalls = []\n",
    "    for t in range(T):\n",
    "        d, r, *_ = dice_and_recall(our[t].astype(np.uint8), sam[t].astype(np.uint8))\n",
    "        dices.append(d); recalls.append(r)\n",
    "    print(f\"Macro Dice={np.mean(dices):.4f}, Macro Recall={np.mean(recalls):.4f}, Frames={T}\")\n",
    "else:\n",
    "    print(\"Drop two matching .npy stacks into /mnt/data and update the paths above to compute metrics.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a31e610",
   "metadata": {},
   "source": [
    "## 6) (Optional) Live RealSense → MJPEG over HTTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8a0326",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This mirrors your streaming server in a cell for convenience.\n",
    "# It requires: pyrealsense2, Flask, and a connected RealSense camera.\n",
    "import os, time, threading\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "try:\n",
    "    import pyrealsense2 as rs\n",
    "    from flask import Flask, Response\n",
    "    have_live = True\n",
    "except Exception as e:\n",
    "    have_live = False\n",
    "    print(\"Live demo dependencies missing or no camera:\", e)\n",
    "\n",
    "if have_live:\n",
    "    def run_server(port=5001, jpeg_quality=80, preview_width=640, save=False):\n",
    "        pipeline = rs.pipeline(); config = rs.config()\n",
    "        W,H,FPS = 640,480,30\n",
    "        config.enable_stream(rs.stream.color, W, H, rs.format.bgr8, FPS)\n",
    "        config.enable_stream(rs.stream.depth, W, H, rs.format.z16, FPS)\n",
    "        profile = pipeline.start(config)\n",
    "        align = rs.align(rs.stream.color)\n",
    "\n",
    "        # warm up model\n",
    "        _ = mp.detect_faces(np.zeros((H,W,3), np.uint8))\n",
    "\n",
    "        q = deque(maxlen=1)\n",
    "        stop = False\n",
    "\n",
    "        def cap():\n",
    "            while not stop:\n",
    "                f = pipeline.wait_for_frames()\n",
    "                f = align.process(f)\n",
    "                c = f.get_color_frame()\n",
    "                d = f.get_depth_frame()\n",
    "                if c and d:\n",
    "                    q.append((np.asanyarray(c.get_data()), np.asanyarray(d.get_data())))\n",
    "        t = threading.Thread(target=cap, daemon=True); t.start()\n",
    "\n",
    "        app = Flask(__name__)\n",
    "        latest = {\"buf\": None, \"seq\": 0}\n",
    "        lock = threading.Lock()\n",
    "        cond = threading.Condition(lock)\n",
    "\n",
    "        def publisher():\n",
    "            while not stop:\n",
    "                if not q:\n",
    "                    time.sleep(0.001); continue\n",
    "                color, depth = q[-1]\n",
    "                boxes = mp.detect_faces(color)\n",
    "                mask = mp.build_mask_numpy(depth, boxes, mp.kernel, mp._calc_depth_profile)\n",
    "                view = mp.fast_pixelate(color, mask, block=mp.anon_block, noise=mp.anon_noise)\n",
    "                ok, buf = cv2.imencode(\".jpg\", view, [int(cv2.IMWRITE_JPEG_QUALITY), jpeg_quality])\n",
    "                if ok:\n",
    "                    with lock:\n",
    "                        latest[\"buf\"] = buf\n",
    "                        latest[\"seq\"] += 1\n",
    "                        cond.notify_all()\n",
    "        threading.Thread(target=publisher, daemon=True).start()\n",
    "\n",
    "        @app.route(\"/view\")\n",
    "        def view():\n",
    "            def gen():\n",
    "                boundary = b\"--frame\\r\\n\"; headers = b\"Content-Type: image/jpeg\\r\\n\\r\\n\"\n",
    "                last = -1\n",
    "                while True:\n",
    "                    with lock:\n",
    "                        cond.wait_for(lambda: latest[\"seq\"] != last)\n",
    "                        last = latest[\"seq\"]; buf = latest[\"buf\"]\n",
    "                    yield boundary + headers + buf.tobytes() + b\"\\r\\n\"\n",
    "            return Response(gen(), mimetype=\"multipart/x-mixed-replace; boundary=frame\")\n",
    "\n",
    "        print(f\"Open http://localhost:{port}/view  (SSH: ssh -L {port}:localhost:{port} <user>@jetson)\")\n",
    "        app.run(host=\"0.0.0.0\", port=port, threaded=True, use_reloader=False)\n",
    "        stop = True; pipeline.stop()\n",
    "\n",
    "    # To launch, uncomment:\n",
    "    # run_server(port=5001, jpeg_quality=80, preview_width=640, save=False)\n",
    "else:\n",
    "    print(\"Install pyrealsense2 and Flask on the Jetson to run the live server.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5961b3a9",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Troubleshooting\n",
    "\n",
    "- **`cuda.is_available() == False`**: verify JetPack/CUDA install and use the correct NVIDIA PyTorch wheel for your JetPack.\n",
    "- **`onnxruntime` missing CUDA/TensorRT providers**: install `onnxruntime-gpu` for Jetson (Jetson AI Lab wheel), confirm `get_available_providers()` lists `CUDAExecutionProvider` and `TensorrtExecutionProvider` (if configured).\n",
    "- **RealSense errors**: check `udev` rules and that `pyrealsense2` matches your firmware; try `sudo apt install librealsense2-utils` and `realsense-viewer`.\n",
    "- **OOM / crashes building torchvision**: add swap, limit builds to `-j1`, or skip torchvision and use OpenCV for transforms.\n",
    "- **Flask stream not visible**: open `/view` URL; if remote, use SSH tunnel: `ssh -L 5001:localhost:5001 user@jetson`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jetson-pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
